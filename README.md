# CKD_EHR
![Solid／Status／Star(1)(1)](https://github.com/user-attachments/assets/bb1a08b8-fb73-467e-841f-0dfcdcb7f133)  Electronic Health Records (EHR)-based disease prediction models have demon- strated significant clinical value in promoting precision medicine and enabling early intervention.


![Solid／Status／Star(1)(1)](https://github.com/user-attachments/assets/a2493392-0fef-4161-bb10-7ff9ba9af884)  However, existing large language models face two major challenges: insufficient representation of medical knowledge and low efficiency in clinical deployment. 
To address these challenges, this study proposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which achieves efficient and accurate disease risk prediction through knowledge distil- lation techniques. Specifically, this method first performs domain adaptation fine-tuning of Qwen2.5-7B using medical knowledge-enhanced data. Subse- quently, interpretable soft labels are generated through a multi-granularity attention distillation mechanism. Finally, the distilled knowledge is trans- ferred to a lightweight BERT model. 


![Solid／Status／Star(1)(1)](https://github.com/user-attachments/assets/be67e7a1-0fcf-49bf-93c9-77c60798fcda)  This innovative solution not only greatly improves resource utilization efficiency but also significantly enhances the accuracy and timeliness of diagnosis, providing a practical technical approach for resource optimization in clinical settings.

#  Frame
<img width="1990" height="1129" alt="fig1" src="https://github.com/user-attachments/assets/dbe93221-7186-43ce-9645-1c684fe851a1" />

#   Data Format
All data files are in **JSONL** format (one JSON object per line).  
### `name_train.json` / `name_val.json`
Each line is a training sample:

```json
{
  "instruction": "Determine that the patient has one or more of the following diseases at the next visit: Acute and unspecified renal failure, Acute cerebrovascular disease, ... , Shock",
  "input": "The patient-acquired disease is ... The patient had used the following medication: ... The surgical operation performed by the patient: ...",
  "output": "Disease that the patient may acquire: Diabetes mellitus without complication, Essential hypertension"
}
```
---

### `hands_name_train.json` / `hands_name_val.json`
These files store **soft labels** (probabilities) generated by the teacher model.  
Format: a JSON array (Python list) of dictionaries, one per sample:

```json
[
  {
    "Acute and unspecified renal failure": 0.01,
    "Acute cerebrovascular disease": 0.02,
    "...": 0.0,
    "Shock": 0.03
  },
  ...
]
```
- Keys: 25 disease names (same set and order as in `instruction`).
- Values: predicted probabilities (`0.0–1.0`) from the teacher’s classification head.

---
##  LoRA Fine-tuning
Teacher model LoRA fine-tuning is done **outside this repository** using [LLaMA-Factory].  
This code assumes you already have a LoRA-finetuned model checkpoint.
High-level steps:
1. **Prepare SFT data **  
   - Use `name_train.json` / `name_val.json` as SFT data 
   - Ensure the `instruction` + `input` + `output` format matches your LLaMA-Factory config.

2. **Run LoRA fine-tuning **  
   - Select base model (e.g., `Qwen/Qwen2.5-7B-Instruct`).  
   - Configure LLaMA-Factory for LoRA fine-tuning.  
   - Train to obtain a LoRA checkpoint, e.g.:  
     `./lora/model`  

3. **Record LoRA path 在本项目中配置路径**  
   - In this project, the LoRA path is referenced as:
     ```python
     LORA_WEIGHTS_PATH = "./lora/model"
     ```
   - Adjust this path to your actual LoRA checkpoint location.

---
##  Running Pipeline 
Project structure:
```text
.
├── data
│   ├── name_train.json
│   ├── name_val.json
│   ├── hands_name_train.json
│   └── hands_name_val.json
├── lora
│   ├── model
│   │   ├── ...  #  Place the LoRA-tuned model/adapter file here
│   └── teacher_classification_head.pt
├── results
├── train_teacher_head.py
├── hands.py
└── main.py
```
### Step 1: Train Teacher Classification Head  
```bash
python train_teacher_head.py
```

- Reads `./data/name_train.json` and `./data/name_val.json` (JSONL format).
- Uses the LoRA-finetuned LLM as a frozen base.
- Trains only the **linear classification head** on top of the last-token hidden state.
- Saves the head weights to:

```text
./lora/teacher_classification_head.pt
```

---
### Step 2: Generate Soft Labels with Teacher  
```bash
python hands.py
```

- Loads:
  - Base LLM + LoRA weights  
  - `teacher_classification_head.pt`
- For each sample in `name_train.json` and `name_val.json`:
  - Encodes `instruction + input` with the same chat template as in training.
  - Computes 25-dim probabilities via the classification head.
- Writes soft labels to:

```text
./data/hands_name_train.json
./data/hands_name_val.json
```

---
### Step 3: Train and Evaluate Student BERT  
```bash
python main.py
```

- Uses:
  - Hard labels: derived from `output` in `name_train.json` + `name_val.json` (25-dim one-hot).
  - Soft labels: from `hands_name_train.json` + `hands_name_val.json` (25-dim probabilities).
- Merges train+val, then splits into **train/validation/test** using the **same shuffled indices** for:
  - inputs,
  - hard labels,
  - soft labels  
  to ensure perfect alignment.
- Trains `bert-base-uncased` multi-label classifier with a combined hard+soft loss.
- Saves:
  - Best model: `./results/heads_results0.9/best_model.pt`
  - Test metrics appended to: `./results/test_metrics.txt`
  - Intermediate arrays: `./results/heads_results0.9/test_results.pt`

---












